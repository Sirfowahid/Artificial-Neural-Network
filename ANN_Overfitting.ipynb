{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZonlkJmsycshddPCg1FV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirfowahid/Artificial-Neural-Network/blob/master/ANN_Overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H9AmmVshxqqP"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# new!\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset (comes with seaborn)\n",
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "\n",
        "# convert from pandas dataframe to tensor\n",
        "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
        "\n",
        "# transform species to number\n",
        "labels = torch.zeros(len(data), dtype=torch.long)\n",
        "# labels[iris.species=='setosa'] = 0 # don't need!\n",
        "labels[iris.species=='versicolor'] = 1\n",
        "labels[iris.species=='virginica'] = 2"
      ],
      "metadata": {
        "id": "2jClTh-exrvk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create our fake dataset\n",
        "\n",
        "fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
        "fakelabels = np.arange(10)>4\n",
        "print(fakedata), print(' ')\n",
        "print(fakelabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qIoy7cMxwTB",
        "outputId": "c50981cb-fc4d-4f0f-c43e-7b3b949b3a35"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 11  12  13  14]\n",
            " [ 21  22  23  24]\n",
            " [ 31  32  33  34]\n",
            " [ 41  42  43  44]\n",
            " [ 51  52  53  54]\n",
            " [ 61  62  63  64]\n",
            " [ 71  72  73  74]\n",
            " [ 81  82  83  84]\n",
            " [ 91  92  93  94]\n",
            " [101 102 103 104]]\n",
            " \n",
            "[False False False False False  True  True  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader object with all data\n",
        "fakedataLdr = DataLoader(fakedata, shuffle=True)\n",
        "print( fakedataLdr )\n",
        "print( fakedataLdr.batch_size )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVGOvegnx6Dj",
        "outputId": "d0393f17-9ff7-455f-f652-38c30602a436"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fd3963d3cd0>\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the data\n",
        "for i,oneSample in enumerate(fakedataLdr):\n",
        "  print(i,oneSample,oneSample.shape)\n",
        "\n",
        "# but where are the labels??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI6JL0KCx8fk",
        "outputId": "cca30890-4e26-4053-d910-1e7119252695"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([[91, 92, 93, 94]]) torch.Size([1, 4])\n",
            "1 tensor([[101, 102, 103, 104]]) torch.Size([1, 4])\n",
            "2 tensor([[61, 62, 63, 64]]) torch.Size([1, 4])\n",
            "3 tensor([[11, 12, 13, 14]]) torch.Size([1, 4])\n",
            "4 tensor([[41, 42, 43, 44]]) torch.Size([1, 4])\n",
            "5 tensor([[21, 22, 23, 24]]) torch.Size([1, 4])\n",
            "6 tensor([[31, 32, 33, 34]]) torch.Size([1, 4])\n",
            "7 tensor([[51, 52, 53, 54]]) torch.Size([1, 4])\n",
            "8 tensor([[71, 72, 73, 74]]) torch.Size([1, 4])\n",
            "9 tensor([[81, 82, 83, 84]]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to create a Dataset that contains the data and labels\n",
        "fakeDataset = torch.utils.data.TensorDataset(torch.Tensor(fakedata),torch.Tensor(fakelabels))\n",
        "print( fakeDataset.tensors ), print(' ')\n",
        "\n",
        "# then create another DataLoader\n",
        "fakedataLdr = DataLoader(fakeDataset, shuffle=True)\n",
        "\n",
        "# iterate through the data\n",
        "for dat,lab in fakedataLdr:\n",
        "  print(dat,lab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC7OiehvyAvg",
        "outputId": "9ecfefe8-55fb-42ff-f477-4a4c944feb01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[ 11.,  12.,  13.,  14.],\n",
            "        [ 21.,  22.,  23.,  24.],\n",
            "        [ 31.,  32.,  33.,  34.],\n",
            "        [ 41.,  42.,  43.,  44.],\n",
            "        [ 51.,  52.,  53.,  54.],\n",
            "        [ 61.,  62.,  63.,  64.],\n",
            "        [ 71.,  72.,  73.,  74.],\n",
            "        [ 81.,  82.,  83.,  84.],\n",
            "        [ 91.,  92.,  93.,  94.],\n",
            "        [101., 102., 103., 104.]]), tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]))\n",
            " \n",
            "tensor([[31., 32., 33., 34.]]) tensor([0.])\n",
            "tensor([[21., 22., 23., 24.]]) tensor([0.])\n",
            "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
            "tensor([[101., 102., 103., 104.]]) tensor([1.])\n",
            "tensor([[91., 92., 93., 94.]]) tensor([1.])\n",
            "tensor([[81., 82., 83., 84.]]) tensor([1.])\n",
            "tensor([[71., 72., 73., 74.]]) tensor([1.])\n",
            "tensor([[11., 12., 13., 14.]]) tensor([0.])\n",
            "tensor([[41., 42., 43., 44.]]) tensor([0.])\n",
            "tensor([[61., 62., 63., 64.]]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use scikitlearn to split the data\n",
        "train_data,test_data, train_labels,test_labels = train_test_split(fakedata, fakelabels, test_size=.2)\n",
        "\n",
        "# then convert them into PyTorch Datasets\n",
        "train_data = torch.utils.data.TensorDataset(\n",
        "     torch.Tensor(train_data),torch.Tensor(train_labels))\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(\n",
        "     torch.Tensor(test_data),torch.Tensor(test_labels))\n",
        "\n",
        "# finally, translate into dataloader objects\n",
        "# notice the batches (see next cell)!\n",
        "train_loader = DataLoader(train_data,batch_size=4)\n",
        "test_loader  = DataLoader(test_data)"
      ],
      "metadata": {
        "id": "YiFZ7nxCyE8P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine the contents of the dataloader (batching is an advantage of dataloader!)\n",
        "print('TRAINING DATA')\n",
        "for batch,label in train_loader: # iterable\n",
        "  print(batch,label)\n",
        "  print(' ')\n",
        "\n",
        "\n",
        "print(' ')\n",
        "print('TESTING DATA')\n",
        "for batch,label in test_loader: # iterable\n",
        "  print(batch,label)\n",
        "  print(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGb2NM6lyRCp",
        "outputId": "ae227872-c479-4672-b2be-205ca42026f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "tensor([[81., 82., 83., 84.],\n",
            "        [71., 72., 73., 74.],\n",
            "        [41., 42., 43., 44.],\n",
            "        [31., 32., 33., 34.]]) tensor([1., 1., 0., 0.])\n",
            " \n",
            "tensor([[11., 12., 13., 14.],\n",
            "        [21., 22., 23., 24.],\n",
            "        [91., 92., 93., 94.],\n",
            "        [61., 62., 63., 64.]]) tensor([0., 0., 1., 1.])\n",
            " \n",
            " \n",
            "TESTING DATA\n",
            "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
            " \n",
            "tensor([[101., 102., 103., 104.]]) tensor([1.])\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVqqgMRLyphi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}